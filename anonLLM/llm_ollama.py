import time
import json
import requests
from pydantic import BaseModel, ValidationError, ConfigDict
from typing import Type, Optional
import os
from anonLLM.anonymizer import Anonymizer
from anonLLM.deanonymizer import Deanonymizer
from autoprint import AutoPrint

class OllamaLanguageModel:
    def __init__(self, model="mistral", temperature=0.5, anonymize=True, base_url="http://localhost:11434"):
        self.anonymize = anonymize
        self.base_url = base_url
        self.model = model
        self.temperature = temperature

        if self.anonymize:
            self.anonymizer = Anonymizer()
            self.deanonymizer = Deanonymizer()

    def generate(self, prompt: str, output_format: Optional[Type[BaseModel]] = None,
                 n_completions: int = 1, max_tokens: int = None):

        print("\nğŸ“Œ Báº¯t Ä‘áº§u generate()")
        print(f"ğŸ”¸ Prompt gá»‘c: {prompt}")
        logger_before = AutoPrint(log_file="log/Before.txt", timestamp=True)
        logger_after = AutoPrint(log_file="log/After.txt", timestamp=True)
        logger_map = AutoPrint(log_file="log/Map.txt", timestamp=True)
        logger_before.print(f"ğŸ”¸ Prompt gá»‘c: {prompt}")
        if self.anonymize:
            print("ğŸ” Äang thá»±c hiá»‡n áº©n danh hÃ³a dá»¯ liá»‡u...")
            anonymized_prompt, mappings = self.anonymizer.anonymize_data(prompt)
            print(f"âœ… Prompt sau khi áº©n danh: {anonymized_prompt}")
            logger_after.print(f"âœ… Prompt sau khi áº©n danh: {anonymized_prompt}")
            print(f"ğŸ“„ Mappings: {mappings}")
            logger_map.print(f"ğŸ“„ Mappings: {mappings}")
        else:
            anonymized_prompt, mappings = prompt, None
            print("âš ï¸ KhÃ´ng thá»±c hiá»‡n áº©n danh hÃ³a.")

        valid_responses = []

        while len(valid_responses) < n_completions:
            try:
                print("\nğŸš€ Gá»­i yÃªu cáº§u tá»›i mÃ´ hÃ¬nh Ollama...")

                system_message = "You are a helpful assistant."
                if output_format:
                    system_message += f" Respond in a JSON format that contains the following keys: {self._model_structure_repr(output_format)}"

                full_prompt = f"{system_message}\n{anonymized_prompt}"
                print(f"ğŸ“¤ Full prompt gá»­i Ä‘i:\n{full_prompt}")

                response = requests.post(
                    f"{self.base_url}/api/generate",
                    json={
                        "model": self.model,
                        "prompt": full_prompt,
                        "temperature": self.temperature
                    },
                    stream=True  # Quan trá»ng: enable streaming Ä‘á»ƒ nháº­n tá»«ng dÃ²ng JSON
                )

                print(f"ğŸ“¥ Pháº£n há»“i nháº­n Ä‘Æ°á»£c: {response.status_code}")
                if response.status_code != 200:
                    raise RuntimeError(f"âŒ Lá»—i tá»« Ollama: {response.text}")

                # Ná»‘i tá»«ng dÃ²ng JSON thÃ nh chuá»—i text hoÃ n chá»‰nh
                text = ""
                for line in response.iter_lines():
                    if line:
                        try:
                            data = json.loads(line.decode("utf-8"))
                            text += data.get("response", "")
                        except json.JSONDecodeError as e:
                            print(f"âŒ Lá»—i khi decode JSON dÃ²ng: {line}\n{e}")

                print(f"ğŸ§¾ VÄƒn báº£n pháº£n há»“i tá»•ng há»£p:\n{text}")

                if output_format:
                    try:
                        parsed = json.loads(text)
                        print("ğŸ” Äang kiá»ƒm tra JSON cÃ³ há»£p lá»‡ theo Ä‘á»‹nh dáº¡ng yÃªu cáº§u khÃ´ng...")
                        if self._is_valid_json_for_model(text, output_format):
                            print("âœ… JSON há»£p lá»‡.")
                            valid_responses.append(parsed)
                        else:
                            print("âŒ JSON khÃ´ng há»£p lá»‡.")
                    except json.JSONDecodeError as e:
                        print(f"âŒ Lá»—i khi parse JSON: {e}")
                else:
                    print("ğŸ“„ KhÃ´ng yÃªu cáº§u Ä‘á»‹nh dáº¡ng JSON => thÃªm pháº£n há»“i raw.")
                    valid_responses.append(text)

            except Exception as err:
                print(f"â— Exception xáº£y ra: {err}")
                break

        def _deanonymize(response):
            print(f"ğŸ”“ Gá»¡ áº©n danh pháº£n há»“i: {response}")
            if output_format:
                for key, value in response.items():
                    response[key] = self.deanonymizer.deanonymize(value, mappings)
                return output_format.model_validate(response)
            else:
                return self.deanonymizer.deanonymize(response, mappings)

        if not valid_responses:
            raise ValueError("âŒ KhÃ´ng cÃ³ pháº£n há»“i há»£p lá»‡ tá»« mÃ´ hÃ¬nh.")

        deanonymized_responses = [_deanonymize(res) if self.anonymize else res
                                  for res in valid_responses]

        result = deanonymized_responses[0] if n_completions == 1 else deanonymized_responses
        print(f"\nâœ… Pháº£n há»“i cuá»‘i cÃ¹ng (sau khi gá»¡ áº©n danh náº¿u cÃ³):\n{result}")
        return result

    def _model_structure_repr(self, model: Type[BaseModel]) -> str:
        fields = model.__annotations__
        return ', '.join(f'{key}: {value}' for key, value in fields.items())

    def _is_valid_json_for_model(self, text: str, model: Type[BaseModel]) -> bool:
        model.model_config = ConfigDict(strict=True)
        try:
            parsed_data = json.loads(text)
            model(**parsed_data)
            return True
        except (json.JSONDecodeError, ValidationError) as e:
            print(f"âŒ Validation failed: {e}")
            return False
