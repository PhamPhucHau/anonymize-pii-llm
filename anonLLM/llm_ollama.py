import time
import json
import requests
from pydantic import BaseModel, ValidationError, ConfigDict
from typing import Type, Optional
import os
from anonLLM.anonymizer import Anonymizer
from anonLLM.deanonymizer import Deanonymizer
from logger import Logger


class OllamaLanguageModel:
    def __init__(self, model="mistral", temperature=0.5, anonymize=True, base_url="http://localhost:11434"):
        self.anonymize = anonymize
        self.base_url = base_url
        self.model = model
        self.temperature = temperature

        if self.anonymize:
            self.anonymizer = Anonymizer()
            self.deanonymizer = Deanonymizer()

    def generate(self, prompt: str, output_format: Optional[Type[BaseModel]] = None,
                 n_completions: int = 1, max_tokens: int = None):

        print("\nüìå B·∫Øt ƒë·∫ßu generate()")
        print(f"üî∏ Prompt g·ªëc: {prompt}")
        Logger.save_text_to_file('output', 'prompt.txt', prompt)
        if self.anonymize:
            print("üîê ƒêang th·ª±c hi·ªán ·∫©n danh h√≥a d·ªØ li·ªáu...")
            anonymized_prompt, mappings = self.anonymizer.anonymize_data(prompt)
            print(f"‚úÖ Prompt sau khi ·∫©n danh: {anonymized_prompt}")
            Logger.save_text_to_file('output', 'prompt_anonimize.txt', anonymized_prompt)
            print(f"üìÑ Mappings: {mappings}")
            Logger.save_text_to_file('output'
            , 'mappings.txt', str(mappings))
        else:
            anonymized_prompt, mappings = prompt, None
            print("‚ö†Ô∏è Kh√¥ng th·ª±c hi·ªán ·∫©n danh h√≥a.")
        return;
        valid_responses = []

        while len(valid_responses) < n_completions:
            try:
                print("\nüöÄ G·ª≠i y√™u c·∫ßu t·ªõi m√¥ h√¨nh Ollama...")

                system_message = "You are a helpful assistant."
                if output_format:
                    system_message += f" Respond in a JSON format that contains the following keys: {self._model_structure_repr(output_format)}"

                full_prompt = f"{system_message}\n{anonymized_prompt}"
                print(f"üì§ Full prompt g·ª≠i ƒëi:\n{full_prompt}")

                response = requests.post(
                    f"{self.base_url}/api/generate",
                    json={
                        "model": self.model,
                        "prompt": full_prompt,
                        "temperature": self.temperature
                    },
                    stream=True  # Quan tr·ªçng: enable streaming ƒë·ªÉ nh·∫≠n t·ª´ng d√≤ng JSON
                )

                print(f"üì• Ph·∫£n h·ªìi nh·∫≠n ƒë∆∞·ª£c: {response.status_code}")
                if response.status_code != 200:
                    raise RuntimeError(f"‚ùå L·ªói t·ª´ Ollama: {response.text}")

                # N·ªëi t·ª´ng d√≤ng JSON th√†nh chu·ªói text ho√†n ch·ªânh
                text = ""
                for line in response.iter_lines():
                    if line:
                        try:
                            data = json.loads(line.decode("utf-8"))
                            text += data.get("response", "")
                        except json.JSONDecodeError as e:
                            print(f"‚ùå L·ªói khi decode JSON d√≤ng: {line}\n{e}")

                print(f"üßæ VƒÉn b·∫£n ph·∫£n h·ªìi t·ªïng h·ª£p:\n{text}")

                if output_format:
                    try:
                        parsed = json.loads(text)
                        print("üîç ƒêang ki·ªÉm tra JSON c√≥ h·ª£p l·ªá theo ƒë·ªãnh d·∫°ng y√™u c·∫ßu kh√¥ng...")
                        if self._is_valid_json_for_model(text, output_format):
                            print("‚úÖ JSON h·ª£p l·ªá.")
                            valid_responses.append(parsed)
                        else:
                            print("‚ùå JSON kh√¥ng h·ª£p l·ªá.")
                    except json.JSONDecodeError as e:
                        print(f"‚ùå L·ªói khi parse JSON: {e}")
                else:
                    print("üìÑ Kh√¥ng y√™u c·∫ßu ƒë·ªãnh d·∫°ng JSON => th√™m ph·∫£n h·ªìi raw.")
                    valid_responses.append(text)

            except Exception as err:
                print(f"‚ùó Exception x·∫£y ra: {err}")
                break

        def _deanonymize(response):
            print(f"üîì G·ª° ·∫©n danh ph·∫£n h·ªìi: {response}")
            if output_format:
                for key, value in response.items():
                    response[key] = self.deanonymizer.deanonymize(value, mappings)
                return output_format.model_validate(response)
            else:
                return self.deanonymizer.deanonymize(response, mappings)

        if not valid_responses:
            raise ValueError("‚ùå Kh√¥ng c√≥ ph·∫£n h·ªìi h·ª£p l·ªá t·ª´ m√¥ h√¨nh.")

        deanonymized_responses = [_deanonymize(res) if self.anonymize else res
                                  for res in valid_responses]

        result = deanonymized_responses[0] if n_completions == 1 else deanonymized_responses
        print(f"\n‚úÖ Ph·∫£n h·ªìi cu·ªëi c√πng (sau khi g·ª° ·∫©n danh n·∫øu c√≥):\n{result}")
        return result

    def _model_structure_repr(self, model: Type[BaseModel]) -> str:
        fields = model.__annotations__
        return ', '.join(f'{key}: {value}' for key, value in fields.items())

    def _is_valid_json_for_model(self, text: str, model: Type[BaseModel]) -> bool:
        model.model_config = ConfigDict(strict=True)
        try:
            parsed_data = json.loads(text)
            model(**parsed_data)
            return True
        except (json.JSONDecodeError, ValidationError) as e:
            print(f"‚ùå Validation failed: {e}")
            return False
